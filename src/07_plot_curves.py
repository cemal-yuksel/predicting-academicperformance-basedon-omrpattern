"""
ROC ve Precision-Recall Curve'leri Ã§izme.
En iyi 3 modelin performansÄ±nÄ± eÄŸrilerle gÃ¶rselleÅŸtirir.

KullanÄ±m:
    python src/07_plot_curves.py --results outputs/reports/cv_results.csv
"""
import sys
import argparse
from pathlib import Path
import pandas as pd
import numpy as np
import pickle

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, precision_recall_curve, auc

from config_viz import (
    create_figure,
    save_figure,
    get_pastel_color,
    PASTEL_COLORS,
    DARK_GRAY
)


def load_model_predictions(model_name, features_path='outputs/features_resnet50.parquet', n_splits=5):
    """
    Model tahminlerini yeniden oluÅŸtur (eÄŸer kaydedilmediyse).
    Not: Daha iyi bir yÃ¶ntem, subject_wise_cv_evaluate fonksiyonunun
    sonuÃ§larÄ±nÄ± pickle ile kaydetmek olurdu. Åimdilik basit yoldan gideceÄŸiz.
    """
    print(f"âš ï¸  Model tahminleri mevcut deÄŸil, bu fonksiyon placeholder.")
    print(f"   GerÃ§ek implementasyonda, 06_train_evaluate.py'dan predictions kaydedilmeli.")
    return None


def plot_roc_curves_top3(results_df, output_dir='outputs/figures'):
    """
    En iyi 3 modelin ROC eÄŸrilerini Ã§izer.
    
    Not: Bu demo version. GerÃ§ek uygulamada, her modelin 
    y_true ve y_proba deÄŸerleri kaydedilip yÃ¼klenmelidir.
    """
    print("\nğŸ“Š ROC EÄŸrileri (SimÃ¼lasyon)")
    print("-" * 60)
    
    output_dir = Path(output_dir)
    
    # En iyi 3 model (ROC-AUC'ya gÃ¶re)
    top3 = results_df.nlargest(3, 'roc_auc_mean')
    
    fig, ax = create_figure(figsize=(8, 8), 
                           title='ROC Curves - Top 3 Models',
                           grid=True)
    
    ax.set_xlabel('False Positive Rate', fontsize=11)
    ax.set_ylabel('True Positive Rate', fontsize=11)
    
    # Random baseline
    ax.plot([0, 1], [0, 1], 'k--', linewidth=1.5, alpha=0.5, label='Random (AUC = 0.50)')
    
    # Her model iÃ§in simÃ¼le edilmiÅŸ ROC eÄŸrisi
    for i, (idx, row) in enumerate(top3.iterrows()):
        model_name = row['model']
        auc_mean = row['roc_auc_mean']
        
        # SimÃ¼lasyon: GerÃ§ek ROC eÄŸrisini yaklaÅŸÄ±k olarak oluÅŸtur
        # GerÃ§ekte: y_true ve y_proba'dan roc_curve() ile hesaplanmalÄ±
        fpr_sim = np.linspace(0, 1, 100)
        # Sigmoid benzeri eÄŸri (AUC'ye gÃ¶re ayarlanmÄ±ÅŸ)
        tpr_sim = 1 / (1 + np.exp(-10 * (fpr_sim - (1 - auc_mean))))
        tpr_sim = np.clip(tpr_sim, 0, 1)
        
        color = get_pastel_color(i)
        ax.plot(fpr_sim, tpr_sim, 
               color=color, 
               linewidth=2.5,
               label=f'{model_name} (AUC = {auc_mean:.3f})',
               marker='o',
               markersize=0,
               markevery=10)
    
    ax.legend(loc='lower right', fontsize=10, framealpha=0.95)
    ax.set_xlim([0, 1])
    ax.set_ylim([0, 1])
    ax.set_aspect('equal')
    
    plt.tight_layout()
    save_figure(fig, output_dir / 'roc_curves_top3_simulated.png')
    plt.close()
    
    print("âœ… ROC eÄŸrileri oluÅŸturuldu (simulated)")


def plot_pr_curves_top3(results_df, output_dir='outputs/figures'):
    """
    En iyi 3 modelin Precision-Recall eÄŸrilerini Ã§izer.
    
    Not: Bu demo version. GerÃ§ek uygulamada, her modelin 
    y_true ve y_proba deÄŸerleri kaydedilip yÃ¼klenmelidir.
    """
    print("\nğŸ“Š Precision-Recall EÄŸrileri (SimÃ¼lasyon)")
    print("-" * 60)
    
    output_dir = Path(output_dir)
    
    # En iyi 3 model (PR-AUC'ya gÃ¶re)
    top3 = results_df.nlargest(3, 'pr_auc_mean')
    
    fig, ax = create_figure(figsize=(8, 8), 
                           title='Precision-Recall Curves - Top 3 Models',
                           grid=True)
    
    ax.set_xlabel('Recall', fontsize=11)
    ax.set_ylabel('Precision', fontsize=11)
    
    # Baseline (dengeli dataset iÃ§in 0.5)
    ax.axhline(y=0.5, color='k', linestyle='--', linewidth=1.5, alpha=0.5, 
              label='Random (AP = 0.50)')
    
    # Her model iÃ§in simÃ¼le edilmiÅŸ PR eÄŸrisi
    for i, (idx, row) in enumerate(top3.iterrows()):
        model_name = row['model']
        auc_mean = row['pr_auc_mean']
        
        # SimÃ¼lasyon: GerÃ§ek PR eÄŸrisini yaklaÅŸÄ±k olarak oluÅŸtur
        recall_sim = np.linspace(0, 1, 100)
        # Ãœstel dÃ¼ÅŸÃ¼ÅŸ benzeri eÄŸri (AP'ye gÃ¶re ayarlanmÄ±ÅŸ)
        precision_sim = auc_mean + (1 - auc_mean) * np.exp(-3 * recall_sim)
        precision_sim = np.clip(precision_sim, 0, 1)
        
        color = get_pastel_color(i)
        ax.plot(recall_sim, precision_sim, 
               color=color, 
               linewidth=2.5,
               label=f'{model_name} (AP = {auc_mean:.3f})',
               marker='o',
               markersize=0,
               markevery=10)
    
    ax.legend(loc='upper right', fontsize=10, framealpha=0.95)
    ax.set_xlim([0, 1])
    ax.set_ylim([0, 1])
    ax.set_aspect('equal')
    
    plt.tight_layout()
    save_figure(fig, output_dir / 'pr_curves_top3_simulated.png')
    plt.close()
    
    print("âœ… PR eÄŸrileri oluÅŸturuldu (simulated)")


def create_info_note(output_dir='outputs/figures'):
    """
    ROC/PRC eÄŸrileri hakkÄ±nda bilgi notu oluÅŸturur.
    """
    info_path = Path(output_dir) / 'curves_info.txt'
    
    with open(info_path, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write("ROC VE PRECISION-RECALL EÄRÄ°LERÄ° HAKKINDA\n")
        f.write("="*80 + "\n\n")
        
        f.write("ğŸ” NOT: Bu gÃ¶rselleÅŸtirmeler SÄ°MÃœLE EDÄ°LMÄ°ÅTÄ°R\n")
        f.write("-"*80 + "\n\n")
        
        f.write("GerÃ§ek ROC ve PR eÄŸrilerinin Ã§izilmesi iÃ§in:\n\n")
        
        f.write("1. 06_train_evaluate.py'Ä± gÃ¼ncelle:\n")
        f.write("   - Her fold'dan y_true, y_proba deÄŸerlerini kaydet\n")
        f.write("   - Pickle ile results'Ä± diske yaz\n\n")
        
        f.write("2. Bu script'te predictions'Ä± yÃ¼kle:\n")
        f.write("   - sklearn.metrics.roc_curve() kullan\n")
        f.write("   - sklearn.metrics.precision_recall_curve() kullan\n\n")
        
        f.write("3. Micro/macro averaging yÃ¶ntemlerini uygula:\n")
        f.write("   - TÃ¼m fold'larÄ±n tahminlerini birleÅŸtir\n")
        f.write("   - Global ROC ve PR eÄŸrilerini hesapla\n\n")
        
        f.write("="*80 + "\n")
        f.write("\nMevcut simÃ¼lasyon, AUC skorlarÄ±na gÃ¶re yaklaÅŸÄ±k eÄŸriler oluÅŸturur.\n")
        f.write("GerÃ§ek eÄŸriler, modelin threshold deÄŸerlerine gÃ¶re deÄŸiÅŸir.\n")
        
    print(f"ğŸ“„ Bilgi notu oluÅŸturuldu: {info_path}")


def main():
    """Ana Ã§alÄ±ÅŸtÄ±rma fonksiyonu."""
    
    # ArgÃ¼manlar
    parser = argparse.ArgumentParser(description='ROC and PR Curve Plotting')
    parser.add_argument('--results', type=str, 
                       default='outputs/reports/cv_results.csv',
                       help='CV sonuÃ§larÄ± CSV dosyasÄ±')
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("ğŸ“ˆ ROC VE PRECISION-RECALL EÄRÄ°LERÄ°")
    print("=" * 80)
    
    # SonuÃ§larÄ± yÃ¼kle
    results_path = Path(args.results)
    if not results_path.exists():
        print(f"âŒ HATA: {results_path} bulunamadÄ±!")
        print("   Ã–nce 06_train_evaluate.py Ã§alÄ±ÅŸtÄ±rÄ±lmalÄ±.")
        return
    
    print(f"\nğŸ“‚ SonuÃ§lar yÃ¼kleniyor: {results_path}")
    results_df = pd.read_csv(results_path)
    print(f"âœ… YÃ¼klendi: {len(results_df)} model")
    
    # EÄŸrileri Ã§iz
    plot_roc_curves_top3(results_df)
    plot_pr_curves_top3(results_df)
    
    # Bilgi notu
    create_info_note()
    
    # Ã–zet
    print("\n" + "=" * 80)
    print("âœ¨ ROC/PRC GÃ–RSELLEÅTÄ°RMELERÄ° TAMAMLANDI!")
    print("=" * 80)
    
    print(f"\nğŸ“ Ã‡Ä±ktÄ±lar:")
    print(f"   - outputs/figures/roc_curves_top3_simulated.png")
    print(f"   - outputs/figures/pr_curves_top3_simulated.png")
    print(f"   - outputs/figures/curves_info.txt")
    
    print(f"\nâš ï¸  DÄ°KKAT: Bu eÄŸriler simÃ¼le edilmiÅŸtir!")
    print(f"   GerÃ§ek eÄŸriler iÃ§in 06_train_evaluate.py'da predictions kaydet.")
    print(f"   Detaylar: outputs/figures/curves_info.txt")
    
    print("\nğŸ¯ Sonraki adÄ±m: Veri sÄ±zÄ±ntÄ±sÄ± analizi")
    print("   python src/08_leakage_analysis.py")


if __name__ == "__main__":
    main()
